{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v8PTLU9xgdi9","executionInfo":{"status":"ok","timestamp":1732420374838,"user_tz":-540,"elapsed":22511,"user":{"displayName":"김형준","userId":"06685130616941328722"}},"outputId":"f7d5e6fb-e8ad-4039-fd7d-6cb4b5566630"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n"]}],"source":["  from google.colab import drive\n","drive.mount('/gdrive',force_remount=True)\n","\n","import os\n","os.chdir('/gdrive/MyDrive/Colab Notebooks/DDPS_Test')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_tz6N88zv8Ei"},"outputs":[],"source":["# Option.py --------------------------------------------------------------------\n","\n","#import argparse\n","import os\n","import torch\n","import numpy as np\n","import datetime\n","from PIL import Image\n","import sys\n","current_working_directory = os.getcwd()\n","sys.path.append(current_working_directory + '/models')\n","\n","class Options:\n","    def __init__(self):\n","        self.name = 'debug'\n","        self.num_threads = 0\n","        self.n_epoch = 1\n","        self.batch_size = 1\n","        self.batch_size_valid = 2\n","        self.valid_N = 2\n","        self.batch_size_test = 1\n","        self.freq_print = 1\n","        self.freq_valid = 10\n","        self.light_N = 4\n","        self.initial_pattern = 'tri_random'\n","        self.used_loss = 'cosine'\n","        self.lr_light = 3e-1\n","        self.lr_decay_light = 0.3\n","        self.step_size_light = 10\n","        self.fix_light_pattern = False\n","        self.fix_light_position = True\n","        self.load_epoch = 0\n","        self.load_step_start = 0\n","        self.load_latest = False\n","        self.dataset_root = './ApplyData/'\n","        self.save_dir = './results_apply/'\n","        self.light_geometric_calib_fn = './calibration/monitor_pixels_h12w6.npy' #'./calibration/monitor_pixels_h16w9.npy' / './calibration/monitor_pixels_h9w16.npy'\n","        self.load_monitor_light = False\n","        self.light_fn = ''\n","        self.pt_ref_x = 0.\n","        self.pt_ref_y = 0.\n","        self.pt_ref_z = 0.1 #0.1 / 0.5\n","        self.resizing_factor = 1\n","        self.cam_R = 608 #608 / 512\n","        self.cam_C = 456 #456 / 612\n","        self.usePatch = False\n","        self.roi_min_c = 511\n","        self.roi_min_r = 288\n","        self.roi_width = 200\n","        self.roi_height = 200\n","        self.cam_focal_length_pix = 8.110470904e+5 #8.110470904e+5 / 1.1485e+3\n","        self.cam_pitch = 1.0315e-5 #1.0315e-5 / 3.45e-6*2\n","        self.cam_gain = 0.0\n","        self.cam_gain_base = 1.0960\n","        self.static_interval = 1/24\n","        self.noise_sigma = 0.02\n","        self.rendering_scalar = 3.25 #5.681e2/28 / 1.3e2/40\n","        self.light_R = 12 # 16 / 9\n","        self.light_C = 6 # 9 / 16\n","        self.light_pitch = 0.315e-3 * 120 * 2\n","        self.monitor_gamma = 2.2\n","        self.vertical_gap = 226.8 * 1e-3 / 3\n","        self.horizontal_gap = 80.64 * 1e-3\n","        self.weight_normal = 1\n","        self.weight_recon = 5\n","\n","        self.initialized = True\n","\n","    def parse(self, save=True, isTrain=True, parse_args=None):\n","        if not self.initialized:\n","            self.initialize()\n","\n","        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') ## gpu cuda 연산 가능시 사용함 (불가능하면 cpu로 대신 연산)\n","        self.dtype = torch.float32 ## float32 type\n","\n","        self.cam_focal_length = self.cam_focal_length_pix * self.cam_pitch\n","\n","        self.cam_shutter_time = self.static_interval / self.light_N\n","\n","        self.original_R = self.cam_R\n","        self.original_C = self.cam_C\n","\n","        self.cam_R //= self.resizing_factor\n","        self.cam_C //= self.resizing_factor\n","        self.cam_pitch *= self.resizing_factor\n","\n","        if not self.usePatch:\n","            self.roi_height = self.cam_R\n","            self.roi_width = self.cam_C\n","\n","        # Dataset paths\n","        self.tb_dir = os.path.join(self.save_dir, self.name, datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")) ## Output 폴더 생성\n","        if not os.path.exists(self.tb_dir):\n","            os.makedirs(self.tb_dir)\n","\n","        print('------------ Options -------------')\n","        args = vars(self)\n","        print('-------------- End ----------------')\n","\n","        if save:\n","            file_name = os.path.join(self.tb_dir, 'opt.txt')\n","            with open(file_name, 'wt') as opt_file:\n","                opt_file.write('------------ Options -------------\\n')\n","                for k, v in sorted(args.items()):\n","                    opt_file.write('%s: %s\\n' % (str(k), str(v)))\n","                opt_file.write('-------------- End ----------------\\n')\n","\n","        # Light position\n","        light_pos = np.load(self.light_geometric_calib_fn) ## 각 superpixel의 위치\n","        light_pos = np.reshape(light_pos, (self.light_R, self.light_C, 3)) ## npy로 복구 (superpixel 좌표값 데이터)\n","        self.light_pos = torch.tensor(light_pos, dtype=self.dtype, device=self.device) ## (cuda 연산 전용) tensor로 변환\n","        self.light_pos_np = light_pos ## 원본 np 저장\n","\n","        self.illums = torch.zeros((self.light_N, self.light_R, self.light_C, 3), dtype=self.dtype, device=self.device)  # (# of Illum, Illum's Row, Illum's Column, 3)\n","        vmin =  0.1\n","        vmax =  0.9\n","        self.illums[:,:,:,:] = vmin\n","\n","        torch.manual_seed(0)\n","        if self.initial_pattern == 'tri_random':\n","            self.illums[:, :, :, :] = torch.rand(self.light_N, self.light_R, self.light_C, 3)\n","\n","        elif self.initial_pattern == 'gray_noise':\n","            self.illums[:, :, :, :] = torch.normal(mean=0.5, std=0.01, size=(self.light_N, self.light_R, self.light_C, 3))\n","\n","        elif self.initial_pattern == 'mono_random':\n","            temp = torch.rand(self.light_N, self.light_R, self.light_C, 1)\n","            self.illums[:, :, :, :] = torch.tile(temp, (1,1,1,3))\n","\n","        elif self.initial_pattern == 'mono_gradient':\n","            # Gradient\n","            row_indices = torch.arange(self.light_R).float().unsqueeze(1)\n","            col_indices = torch.arange(self.light_C).float().unsqueeze(0)\n","            ones = torch.ones(self.light_R, self.light_C)\n","            dist = row_indices / self.light_R\n","            self.illums[0] = torch.tile((0.1 + 0.8 * (ones - dist)).unsqueeze(-1), (1,1,3))\n","            self.illums[1] = torch.flip(self.illums[0], dims=[0])\n","            dist = col_indices / self.light_C\n","            self.illums[2] = torch.tile((0.1 + 0.8 * (ones - dist)).unsqueeze(-1), (1,1,3))\n","            self.illums[3] = torch.flip(self.illums[2], dims=[1])\n","\n","        elif self.initial_pattern == 'tri_gradient':\n","            # Color Gradient\n","            row_indices = torch.arange(self.light_R).float().unsqueeze(1)\n","            col_indices = torch.arange(self.light_C).float().unsqueeze(0)\n","            ones = torch.ones(self.light_R, self.light_C)\n","            dist = row_indices / self.light_R\n","            self.illums[0,:,:,2] = ((ones - dist))\n","            self.illums[1,:,:,2] = dist\n","            dist = col_indices / self.light_C\n","            self.illums[0,:,:,0] = ((ones - dist))\n","            self.illums[1,:,:,0] = dist\n","            # Compute distance from center of image\n","            dist = torch.sqrt((row_indices - self.light_R/2)**2 + (col_indices - self.light_C/2)**2)\n","            dist_norm = (dist.max() - dist) / dist.max()\n","            intensity = dist_norm * ones\n","            self.illums[0,:,:,1] = intensity\n","            self.illums[1,:,:,1] = ones - intensity\n","\n","        elif self.initial_pattern == 'mono_comnplementary':\n","            # Binary\n","            self.illums[1, :, :self.light_C // 2, :] = vmax\n","            self.illums[0, :, self.light_C // 2:, :] = vmax\n","            self.illums[2, :self.light_R // 2, :, :] = vmax\n","            self.illums[3, self.light_R // 2:, :, :] = vmax\n","\n","        elif self.initial_pattern == 'tri_comnplementary':\n","            # Color binary\n","            self.illums[0, :, :self.light_C // 2, 0] = vmax\n","            self.illums[0, :, self.light_C // 2:, 1] = vmax\n","            self.illums[0, :self.light_R // 2, :, 2] = vmax\n","            self.illums[1, :, :self.light_C // 2, 1] = vmax\n","            self.illums[1, :, self.light_C // 2:, 0] = vmax\n","            self.illums[1, self.light_R // 2:, :, 2] = vmax\n","\n","\n","        elif self.initial_pattern == 'OLAT':\n","            # OLAT\n","            self.illums[0, :1, -1:, :] = vmax\n","            self.illums[1, :1, :1, :] = vmax\n","            self.illums[2, -1:, -1:, :] = vmax\n","            self.illums[3, -1:, :1, :] = vmax\n","\n","        elif self.initial_pattern == 'grouped_OLAT':\n","            # Neighbor OLAT\n","            self.illums[0, :3, -3:, :] = vmax\n","            self.illums[1, :3, :3, :] = vmax\n","            self.illums[2, -3:, -3:, :] = vmax\n","            self.illums[3, -3:, :3, :] = vmax\n","        #self.illums[:, :, :, :] = 0.99 # for Test\n","        self.illums[:, :, :, :] = torch.logit(self.illums)\n","\n","        # Reference point\n","        self.pt_ref = torch.tensor([self.pt_ref_x, self.pt_ref_y, self.pt_ref_z], dtype=self.dtype, device=self.device) ## 미사용 변수\n","\n","        # Reference point\n","        reference_plane = self.compute_ptcloud_from_depth(self.pt_ref_z, 0, 0, self.cam_R, self.cam_C, self.cam_R, self.cam_C, self.cam_pitch, self.cam_focal_length)\n","        reference_plane = torch.tensor(reference_plane, device=self.device, dtype=self.dtype)\n","        self.reference_plane = torch.tile(reference_plane.unsqueeze(0), (self.batch_size, 1, 1, 1))\n","\n","        return self\n","\n","    def compute_ptcloud_from_depth(self, depth, roi_rmin, roi_cmin, roi_height, roi_width, full_height, full_width, pitch, focal_length):\n","        '''\n","        make a point cloud by unprojecting the pixels with depth\n","        '''\n","        if isinstance(depth, float):\n","            pass\n","        else:\n","            depth = depth[roi_rmin:roi_rmin + roi_height, roi_cmin:roi_cmin + roi_width] ## 사실상 미사용\n","        XYZ = np.zeros((roi_height, roi_width, 3), dtype=np.float32)\n","        r, c = np.meshgrid(np.linspace(roi_rmin, roi_rmin + roi_height - 1, roi_height),\n","                              np.linspace(roi_cmin, roi_cmin + roi_width - 1, roi_width),\n","                              indexing='ij')\n","        center_c, center_r = full_width / 2, full_height / 2\n","        XYZ[:, :, 0] = (depth / focal_length) * (c - center_c) * pitch\n","        XYZ[:, :, 1] = (depth / focal_length) * (r - center_r) * pitch\n","        XYZ[:, :, 2] = depth\n","\n","        return XYZ\n","\n","# trainer.py  ------------------------------------------------------------------\n","\n","import torch\n","from torch.autograd import Variable\n","import matplotlib.pyplot as plt\n","import numpy as np\n","# from scipy import interpolate\n","#import utils\n","from PIL import Image\n","import gc\n","import os\n","import datetime\n","\n","def model_results_to_np(model_results, batch_ind=None):\n","    if batch_ind is None:\n","        B = model_results['normal_est'].shape[0]\n","        batch_ind =range(0,B)\n","\n","    results = dict()\n","    results['normal_est'] = model_results['normal_est'][batch_ind, ...].detach().cpu().numpy()\n","    results['albedo_est'] = model_results['albedo_est'][batch_ind, ...].detach().cpu().numpy()\n","    results['depth_est'] = model_results['depth_est'][batch_ind, ...].detach().cpu().numpy()\n","\n","    return results\n","\n","class Trainer:\n","    def __init__(self, opt, reconstructor):\n","\n","        self.opt = opt\n","        self.reconstructor = reconstructor\n","\n","        self.model_results = None\n","        self.optimize_light = not opt.fix_light_pattern\n","        self.optimize_position = not opt.fix_light_position\n","\n","        # Optimization variable parameterization\n","        self.monitor_superpixel_positions = torch.nn.Parameter(self.opt.light_pos)\n","        self.camera_gain = torch.logit(torch.tensor([self.opt.cam_gain], device=self.opt.device, dtype=self.opt.dtype)/48)\n","\n","        # Load monitor\n","        if opt.load_monitor_light:\n","            self.monitor_light_patterns = torch.load(opt.light_fn)\n","\n","    def run_model(self, dataset, idx):\n","\n","        data = dataset[idx]\n","        batch_size = 1\n","\n","        depth = self.opt.reference_plane[:batch_size,:,:,:]\n","        depth = depth.to(device=self.opt.device)\n","\n","        # Render image\n","        I_diffuse = data['imgs']\n","        self.monitor_light_patterns = data['patterns']\n","        mask = data['mask']\n","        incident, _ = self.compute_light_direction(depth, self.monitor_superpixel_positions)\n","\n","        # Reconstruct normal and albedo\n","        recon_output = self.reconstructor.forward(I_diffuse, self.monitor_light_patterns, incident, self.camera_gain, mask)\n","        normal_est, albedo_est, depth_est = (recon_output['normal'], recon_output['albedo'], recon_output['depth'])\n","\n","        model_results = {}\n","        model_results['normal_est'] = normal_est.detach()\n","        model_results['albedo_est'] = albedo_est.detach()\n","        model_results['depth_est'] = depth_est.detach()\n","\n","        return model_results\n","\n","    def compute_light_direction(self, ptcloud, light_pos):\n","        # Compute for point light sources\n","        incident = light_pos.unsqueeze(2).unsqueeze(2).unsqueeze(2) - ptcloud.unsqueeze(0).unsqueeze(0)\n","        incident = incident / (torch.linalg.norm(incident, axis=-1).unsqueeze(-1) + 1e-8)\n","        exitant = -(ptcloud / (torch.linalg.norm(ptcloud, axis=-1).unsqueeze(-1) + 1e-8))\n","\n","        return incident, exitant[None, None, ...]\n","\n","    def run_optimizers_one_step(self, data):\n","\n","        # Backward pass\n","        if self.optimize_light:\n","            self.optimizer_light.zero_grad()\n","\n","        # ----------------------------------------------\n","        self.model_results = self.run_model(data)\n","        self.loss_dict = self.model_results['losses']\n","        loss_sum = sum(self.loss_dict.values())\n","        loss_sum.requires_grad_(True)\n","        loss_sum.backward()\n","\n","        # Step optimizer\n","        if self.optimize_light:\n","            self.optimizer_light.step()\n","        # ----------------------------------------------\n","\n","    def run_schedulers_one_step(self):\n","        if self.optimize_light:\n","            self.scheduler_light.step()\n","\n","    def get_losses(self):\n","        return self.loss_dict\n","\n","    def get_model_results(self):\n","        return self.model_results\n","\n","# Utils.py ---------------------------------------------------------------------\n","\n","import torch\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","#import trainer as trainer_utils\n","import datetime\n","\n","\n","def print_training_status(epoch, n_epoch, step, debug_step):\n","    message = f'(epoch: {epoch}/{n_epoch}, iters: {step}, debug_iters: {debug_step}) '\n","    print(message)\n","\n","\n","def display(opt, writer, model_results, step, mode, batch_index, dir, rendered_image, rendered_error): # @@@@\n","    results = model_results_to_np(model_results, batch_ind=batch_index)\n","    #results = trainer_utils.model_results_to_np(model_results, batch_ind=batch_index)\n","    writer.add_image(f'model_results_{mode+str(batch_index)}/[normal_gt]', ((-results['normal_gt'].transpose((2,0,1))+1)/2), step)\n","    writer.add_image(f'model_results_{mode+str(batch_index)}/[normal_est]', ((-results['normal_est'].transpose((2,0,1))+1)/2), step)\n","    writer.add_image(f'model_results_{mode+str(batch_index)}/[albedo_est]', results['albedo_est'].transpose((2,0,1)), step)\n","    normal_error = torch.sigmoid(rendered_error[batch_index]).detach().cpu().numpy()\n","    normal_error = torch.tensor([normal_error,normal_error,normal_error]).squeeze(1)\n","    writer.add_image(f'model_results_{mode+str(batch_index)}/[normal_err]', normal_error, step)\n","    for i in range(opt.light_N):\n","        rendered_img = rendered_image[batch_index][i].detach().cpu().numpy()\n","        writer.add_image(f'pattern[{i+1}]/{mode+str(batch_index)}[rendered_img]', rendered_img.transpose((2,0,1)), step)\n","\n","def display_pattern(opt, writer, model_results, step, mode, dir, pattern):\n","    Pattern = torch.sigmoid(pattern)\n","    Pattern = Pattern.detach().cpu().numpy()\n","    for i in range(opt.light_N):\n","        writer.add_image(f'pattern[{i+1}]/pattern_img', Pattern[i].transpose((2,0,1)), step)\n","\n","\n","def save_model(monitor_light_patterns, superpixel_position, epoch, step, dir):\n","\n","    if monitor_light_patterns is not None:\n","        torch.save(monitor_light_patterns, os.path.join(dir, f'monitor_light_patterns_epoch{str(epoch).zfill(5)}_step{str(step).zfill(5)}.pth'))\n","        torch.save(monitor_light_patterns, os.path.join(dir, 'monitor_light_patterns_latest.pth'))\n","\n","        torch.save(superpixel_position, os.path.join(dir, f'superpixel_position_epoch{str(epoch).zfill(5)}_step{str(step).zfill(5)}.pth'))\n","        torch.save(superpixel_position, os.path.join(dir, 'superpixel_position_latest.pth'))\n","\n","def save_model_pattern(monitor_light_patterns, epoch, step, dir):\n","    if monitor_light_patterns is not None:\n","        torch.save(monitor_light_patterns, os.path.join(dir, f'monitor_light_patterns_epoch{str(epoch).zfill(5)}_step{str(step).zfill(5)}.pth'))\n","        torch.save(monitor_light_patterns, os.path.join(dir, 'monitor_light_patterns_latest.pth'))\n","\n","def save_model_position(superpixel_position, epoch, step, dir):\n","    if superpixel_position is not None:\n","        torch.save(superpixel_position, os.path.join(dir, f'superpixel_position_epoch{str(epoch).zfill(5)}_step{str(step).zfill(5)}.pth'))\n","        torch.save(superpixel_position, os.path.join(dir, 'superpixel_position_latest.pth'))\n","\n","def load_monitor_light_patterns(outdir, epoch, latest=False):\n","    if latest:\n","        fn = os.path.join(outdir, 'monitor_light_patterns_latest.pth')\n","    else:\n","        fn = os.path.join(outdir, 'monitor_light_patterns_epoch%d.pth' % (epoch))\n","    if not os.path.isfile(fn):\n","        raise FileNotFoundError('%s not exists yet!' % fn)\n","    else:\n","        return torch.load(fn)\n","\n","\n","def load_camera_gain(outdir, epoch, latest=False):\n","    if latest:\n","        fn = os.path.join(outdir, 'camera_gain_latest.pth')\n","    else:\n","        fn = os.path.join(outdir, 'camera_gain_epoch%d.pth' % (epoch))\n","    if not os.path.isfile(fn):\n","        raise FileNotFoundError('%s not exists yet!' % fn)\n","    else:\n","        return torch.load(fn)\n","\n","\n","def cut_edge_batch(target_img):\n","    # torch tensor\n","    h = target_img.size(2)\n","    w = target_img.size(3)\n","\n","    h1 = (h % 8)//2\n","    w1 = (w % 8)//2\n","    h2 = h - ((h % 8)-h1)\n","    w2 = w - ((w % 8)-w1)\n","    target_img = target_img[:, :, h1:h2, w1:w2]\n","    return target_img\n","\n","\n","def cut_edge(target_img):\n","    # numpy ndarray\n","    h = target_img.shape[0]\n","    w = target_img.shape[1]\n","\n","    h1 = (h % 8)//2\n","    w1 = (w % 8)//2\n","    h2 = h - ((h % 8)-h1)\n","    w2 = w - ((w % 8)-w1)\n","    target_img = target_img[h1:h2, w1:w2]\n","    return target_img\n","\n","\n","def visualize3D(opt, rgb, ptcloud, light_pos, camera_pos, reference_plane, reference_point):\n","    # This code visualizes ptcloud, monitor, camera\n","\n","    fig = plt.figure(figsize=(18, 15))\n","    ax = fig.add_subplot(2, 2, 1, projection='3d')\n","    # draw 3D scene\n","    ax.scatter(ptcloud[..., 0], ptcloud[..., 1], ptcloud[..., 2], c=rgb.reshape(-1, 3), marker='.', s=1, alpha=0.25)\n","    ax.set_xlabel('X [m]')\n","    ax.set_ylabel('Y [m]')\n","    ax.set_zlabel('Z [m]')\n","    ax.view_init(-45, -90)\n","    # draw monitor light source\n","    ax.scatter(light_pos[..., 0], light_pos[..., 1], light_pos[..., 2], c='red', marker='*', s=10)\n","    ax.scatter(light_pos[0,0, 0], light_pos[0,0, 1], light_pos[0,0, 2], c='blue', marker='*', s=20)\n","    # draw camera center\n","    ax.scatter(camera_pos[0], camera_pos[1], camera_pos[2], c='blue', marker='o', s=20)\n","    ax.scatter(reference_plane[..., 0], reference_plane[..., 1], reference_plane[..., 2], c=rgb.reshape(-1, 3), marker='.', s=1, alpha=0.25)\n","    ax.scatter(reference_point[0], reference_point[1], reference_point[2], c='green', marker='o', s=20)\n","\n","    ax.set_xlim([-1., 1.])\n","    ax.set_ylim([-1., 1.])\n","    ax.set_zlim([-0., 2.])\n","\n","    ax = fig.add_subplot(2, 2, 2, projection='3d')\n","    # draw 3D scene\n","    ax.scatter(ptcloud[..., 0], ptcloud[..., 1], ptcloud[..., 2], c=rgb.reshape(-1, 3), marker='.', s=1, alpha=0.25)\n","    ax.set_xlabel('X [m]')\n","    ax.set_ylabel('Y [m]')\n","    ax.set_zlabel('Z [m]')\n","    ax.view_init(0, 0)\n","    # draw monitor light source\n","    ax.scatter(light_pos[..., 0], light_pos[..., 1], light_pos[..., 2], c='red', marker='*', s=10)\n","    # draw camera center\n","    ax.scatter(camera_pos[0], camera_pos[1], camera_pos[2], c='blue', marker='o', s=20)\n","    ax.scatter(reference_plane[..., 0], reference_plane[..., 1], reference_plane[..., 2], c=rgb.reshape(-1, 3), marker='.', s=1, alpha=0.25)\n","    ax.scatter(reference_point[0], reference_point[1], reference_point[2], c='green', marker='o', s=20)\n","\n","    ax.set_xlim([-1., 1.])\n","    ax.set_ylim([-1., 1.])\n","    ax.set_zlim([-0., 2.])\n","\n","    ax = fig.add_subplot(2, 2, 3, projection='3d')\n","    # draw 3D scene\n","    ax.scatter(ptcloud[..., 0], ptcloud[..., 1], ptcloud[..., 2], c=rgb.reshape(-1, 3), marker='.', s=1, alpha=0.25)\n","    ax.set_xlabel('X [m]')\n","    ax.set_ylabel('Y [m]')\n","    ax.set_zlabel('Z [m]')\n","    ax.view_init(0, 90)\n","    # draw monitor light source\n","    ax.scatter(light_pos[..., 0], light_pos[..., 1], light_pos[..., 2], c='red', marker='*', s=10)\n","    # draw camera center\n","    ax.scatter(camera_pos[0], camera_pos[1], camera_pos[2], c='blue', marker='o', s=20)\n","    ax.scatter(reference_plane[..., 0], reference_plane[..., 1], reference_plane[..., 2], c=rgb.reshape(-1, 3), marker='.', s=1, alpha=0.25)\n","    ax.scatter(reference_point[0], reference_point[1], reference_point[2], c='green', marker='o', s=20)\n","\n","    ax.set_xlim([-1., 1.])\n","    ax.set_ylim([-1., 1.])\n","    ax.set_zlim([-0., 2.])\n","\n","    ax = fig.add_subplot(2, 2, 4, projection='3d')\n","    # draw 3D scene\n","    ax.scatter(ptcloud[..., 0], ptcloud[..., 1], ptcloud[..., 2], c=rgb.reshape(-1, 3), marker='.', s=1, alpha=0.25)\n","    ax.set_xlabel('X [m]')\n","    ax.set_ylabel('Y [m]')\n","    ax.set_zlabel('Z [m]')\n","    ax.view_init(90, 0)\n","    # draw monitor light source\n","    ax.scatter(light_pos[..., 0], light_pos[..., 1], light_pos[..., 2], c='red', marker='*', s=10)\n","    # draw camera center\n","    ax.scatter(camera_pos[0], camera_pos[1], camera_pos[2], c='blue', marker='o', s=20)\n","    ax.scatter(reference_plane[..., 0], reference_plane[..., 1], reference_plane[..., 2], c=rgb.reshape(-1, 3), marker='.', s=1, alpha=0.25)\n","    ax.scatter(reference_point[0], reference_point[1], reference_point[2], c='green', marker='o', s=20)\n","\n","    ax.set_xlim([-1., 1.])\n","    ax.set_ylim([-1., 1.])\n","    ax.set_zlim([-0., 2.])\n","\n","    plt.savefig(os.path.join(opt.tb_dir, datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + 'pointcloud'), facecolor='#eeeeee', bbox_inches='tight', dpi=300)\n","    plt.close()\n","\n","def visualize_patterns(opt, monitor_light_patterns):\n","    monitor_light_radiance = torch.sigmoid(monitor_light_patterns)\n","\n","    plt.figure(figsize=(10, 2*opt.light_N), constrained_layout=True)\n","    plt.suptitle('Pattern')\n","    for illum_idx in range(opt.light_N):\n","        pattern = (monitor_light_radiance[illum_idx])\n","        r = np.zeros_like(pattern)\n","        g = np.zeros_like(pattern)\n","        b = np.zeros_like(pattern)\n","        r[:, :, 0] = pattern[:, :, 0]\n","        g[:, :, 1] = pattern[:, :, 1]\n","        b[:, :, 2] = pattern[:, :, 2]\n","\n","        r = np.clip(r, 0.0, 1.0)\n","        g = np.clip(g, 0.0, 1.0)\n","        b = np.clip(b, 0.0, 1.0)\n","\n","        plt.subplot(opt.light_N, 4, illum_idx*4+1)\n","        plt.imshow(pattern)\n","        plt.title(f'Light pattern {illum_idx+1} RGB Channel')\n","\n","        plt.subplot(opt.light_N, 4, illum_idx*4+2)\n","        plt.imshow(r)\n","        plt.title(f'Light pattern {illum_idx+1} R Channel')\n","\n","        plt.subplot(opt.light_N, 4, illum_idx*4+3)\n","        plt.imshow(g)\n","        plt.title(f'Light pattern {illum_idx+1} G Channel')\n","\n","        plt.subplot(opt.light_N, 4, illum_idx*4+4)\n","        plt.imshow(b)\n","        plt.title(f'Light pattern {illum_idx+1} B Channel')\n","    plt.savefig(os.path.join(opt.tb_dir, datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + '_0_Monitor_patterns'), facecolor='#eeeeee', bbox_inches='tight', dpi=300)\n","    plt.close()\n","\n","def visualize_GT_data(opt, file_names, monitor_light_patterns, I_diffuse):\n","    batch_size = len(file_names)\n","    for batch_idx in range(batch_size):\n","        plt.figure(figsize=(8, opt.light_N*2), constrained_layout=True)\n","        plt.suptitle(f'Batch {batch_idx+1}: '+file_names[batch_idx])\n","        for illum_idx in range(opt.light_N):\n","            plt.subplot(opt.light_N, 2, illum_idx*2+1)\n","            plt.imshow((monitor_light_patterns[illum_idx]))\n","            plt.title(f'Light pattern {illum_idx+1}')\n","            plt.subplot(opt.light_N, 2, illum_idx*2+2)\n","            plt.imshow(I_diffuse[batch_idx, illum_idx])\n","            plt.title(f'B{batch_idx+1}_L{illum_idx+1}_Diffuse')\n","        plt.savefig(os.path.join(opt.tb_dir, datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f'_1_{batch_idx+1}th_Data_Rendered_images.png'), facecolor='#eeeeee', bbox_inches='tight', dpi=300)\n","        plt.close()\n","\n","def visualize_EST_normal(opt, file_names, normal_gt, normal_est, mask):\n","    batch_size = len(file_names)\n","    for batch_idx in range(batch_size):\n","        plt.figure(figsize=(8,8), constrained_layout=True)\n","        plt.suptitle(f'Batch {batch_idx + 1}: ' + file_names[batch_idx])\n","\n","        plt.subplot(2, 2, 1)\n","        plt.imshow(((-normal_gt[batch_idx]+1)/2))\n","        plt.title(f'Batch{batch_idx+1}_Normal_GT')\n","        plt.colorbar()\n","\n","        plt.subplot(2, 2, 3)\n","        plt.imshow(((-normal_est[batch_idx]+1)/2))\n","        plt.title(f'Batch{batch_idx+1}_Normal_EST')\n","        plt.colorbar()\n","\n","\n","        normal_cos_error = 1 - np.abs((normal_gt[batch_idx] * normal_est[batch_idx]).sum(-1))\n","        normal_angular_error = np.rad2deg(np.arccos((normal_gt[batch_idx] * normal_est[batch_idx]).sum(-1)))\n","\n","        plt.subplot(2, 2, 2)\n","        plt.imshow(normal_cos_error * mask[batch_idx])\n","        plt.colorbar()\n","        plt.title(f'Batch{batch_idx+1}_Normal_Cosine_LOSS')\n","\n","\n","        plt.subplot(2, 2, 4)\n","        plt.imshow(normal_angular_error * mask[batch_idx])\n","        plt.colorbar()\n","        plt.title(f'Batch{batch_idx+1}_Normal_Angular_LOSS')\n","\n","        plt.savefig(os.path.join(opt.tb_dir, datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f'_1_{batch_idx+1}th_Data_EST_Normal.png'), facecolor='#eeeeee', bbox_inches='tight', dpi=300)\n","        plt.close()\n","\n","def visualize_unsup_error(opt, file_names, monitor_light_patterns, I_diffuse, I_diffuse_est, I_diffuse_error):\n","    batch_size = len(file_names)\n","    for batch_idx in range(batch_size):\n","        plt.figure(figsize=(8, opt.light_N*2), constrained_layout=True)\n","        plt.suptitle(f'Batch {batch_idx+1}: '+file_names[batch_idx])\n","        for illum_idx in range(opt.light_N):\n","            plt.subplot(opt.light_N, 4, illum_idx*4+1)\n","            plt.imshow((monitor_light_patterns[illum_idx]))\n","            plt.title(f'Light pattern {illum_idx+1}')\n","\n","            plt.subplot(opt.light_N, 4, illum_idx*4+2)\n","            plt.imshow(I_diffuse[batch_idx, illum_idx])\n","            plt.title(f'B{batch_idx+1}_L{illum_idx+1}_I_GT')\n","\n","            plt.subplot(opt.light_N, 4, illum_idx*4+3)\n","            plt.imshow(I_diffuse_est[batch_idx, illum_idx])\n","            plt.title(f'B{batch_idx+1}_L{illum_idx+1}_I_Rerender')\n","\n","            plt.subplot(opt.light_N, 4, illum_idx*4+4)\n","            plt.imshow(I_diffuse_error[batch_idx, illum_idx])\n","            plt.title(f'B{batch_idx+1}_L{illum_idx+1}_Error')\n","\n","        plt.savefig(os.path.join(opt.tb_dir, datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f'_2_{batch_idx+1}th_Data_Rerender.png'), facecolor='#eeeeee', bbox_inches='tight', dpi=300)\n","        plt.close()\n","\n","# Dataset.py -------------------------------------------------------------------\n","\n","import torch\n","import glob\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from PIL import Image\n","import re\n","import os\n","#from pyntcloud import PyntCloud\n","from os.path import join\n","import random\n","#import models.utils as utils\n","\n","\n","class CreateBasisDataset(torch.utils.data.Dataset):\n","    def __init__(self, opt, list_name):\n","        self.opt = opt\n","        self.scene_names = file_load(os.path.join(opt.dataset_root, list_name))\n","\n","    def __getitem__(self, i):\n","        scene_name = self.scene_names[i]\n","        pattern_dir = os.path.join(self.opt.dataset_root, scene_name, 'Pattern')\n","        pattern_file_names = [str(f).zfill(3)+'.png' for f in range(self.opt.light_N)]\n","        image_dir = os.path.join(self.opt.dataset_root, scene_name, 'Image')\n","        image_file_names = [str(f).zfill(3)+'.png' for f in range(self.opt.light_N)]\n","\n","        vmax = 0.9\n","        vmin = 0.1\n","        patterns = torch.zeros((self.opt.light_N, self.opt.light_R, self.opt.light_C, 3), dtype=self.opt.dtype, device=self.opt.device)\n","        for idx, pat_file in enumerate(pattern_file_names):\n","            pat_path = os.path.join(pattern_dir, pat_file)\n","            pat = Image.open(pat_path)\n","            pat = np.array(pat).astype(np.float32)\n","            pat = pat/255\n","            pat = torch.tensor(pat[:,:,:3], dtype=self.opt.dtype, device=self.opt.device)\n","            pat[pat>vmax] = vmax\n","            pat[pat<vmin] = vmin\n","            pat = torch.logit(pat)\n","            patterns[idx] = pat\n","\n","        imgs = torch.zeros((1, self.opt.light_N, self.opt.cam_R, self.opt.cam_C, 3), dtype=self.opt.dtype, device=self.opt.device)\n","        for idx, img_file in enumerate(image_file_names):\n","            img_path = os.path.join(image_dir, img_file)\n","            img = Image.open(img_path)\n","            img = np.array(img).astype(np.float32)\n","            img = img/255\n","            img = cv2.medianBlur(img, 3)\n","            img = torch.tensor(img[:,:,:3], dtype=self.opt.dtype, device=self.opt.device)\n","            imgs[0][idx] = img\n","        imgs = torch.clamp(imgs, 1e-8, 1)\n","\n","        mask = np.load(os.path.join(self.opt.dataset_root, scene_name, 'geo_normal_img_mask.npy'))\n","        mask[mask!=0] = 1\n","        mask = mask[:,:,0]\n","\n","        kernel = np.ones((7,7), np.uint8)\n","        mask = cv2.erode(mask, kernel, iterations=1)\n","\n","        input_dict = {\n","            'id': i,\n","            'scene': scene_name,\n","            'patterns' : patterns,\n","            'imgs': imgs,\n","            'mask': mask\n","        }\n","        return input_dict\n","\n","    def __len__(self):\n","        return len(self.scene_names)\n","\n","\n","def file_load(path):\n","    # Read data list\n","    data_path = []\n","    f = open(\"{0}.txt\".format(path), 'r')\n","    while True:\n","        line = f.readline()\n","        if not line:\n","            break\n","        data_path.append(line[:-1])\n","    f.close()\n","    return data_path\n","\n","\n","def read_RGB(path):\n","    # RGB for compute diffuse\n","    img = Image.open(path)\n","    img.load()\n","    data = np.asarray(img, dtype=\"int32\")\n","    return data\n","\n","# renderer.py ------------------------------------------------------------------\n","\n","import matplotlib.pyplot as plt\n","#from models.dataset import *\n","import torch.nn.functional as nn\n","import matplotlib.pyplot as plt\n","import torch\n","from scipy.io import loadmat\n","#import utils\n","import datetime\n","import torchvision.transforms as T\n","\n","class LightDeskRenderer:\n","    def __init__(self, opt):\n","        self.opt = opt\n","\n","    def render(self, basis_images, monitor_light_pattern_nonlinear, camera_gain):\n","        batch_size = basis_images.shape[0]\n","\n","        monitor_light_radiance = torch.sigmoid(monitor_light_pattern_nonlinear) ** self.opt.monitor_gamma\n","        monitor_light_radiance = torch.flip(monitor_light_radiance, dims=[2])\n","        monitor_light_radiance = monitor_light_radiance.reshape(self.opt.light_N, -1, 3).unsqueeze(0).unsqueeze(-1)\n","\n","        basis_images = basis_images.permute(0,1,4,2,3)\n","        # weights: [batch, lightN, R*C, 3, H*W]\n","        basis_images = basis_images.reshape(batch_size, self.opt.light_R*self.opt.light_C, 3, -1).unsqueeze(1)\n","        result = monitor_light_radiance * basis_images\n","        result = result.sum(axis=2)\n","        result = result.reshape(batch_size, self.opt.light_N, 3, self.opt.cam_R, self.opt.cam_C)\n","        result = result.permute(0,1,3,4,2)\n","\n","\n","        gain_scalar = self.opt.cam_gain_base ** (torch.sigmoid(camera_gain)*48)\n","\n","        I_diffuse = gain_scalar * (self.opt.rendering_scalar * self.opt.cam_shutter_time * result)\n","        I_diffuse = torch.clamp(I_diffuse, 1e-8, 1)\n","        '''\n","        Sigma = self.opt.Gaussian_sigma\n","        ksize = int(8*Sigma+1)\n","        transform = T.GaussianBlur(kernel_size=(ksize,ksize), sigma=(Sigma,Sigma))\n","\n","        I_diffuse_G = torch.zeros((batch_size, I_diffuse.shape[1], I_diffuse.shape[2], I_diffuse.shape[3], 3), dtype=self.opt.dtype, device=self.opt.device)\n","        for i in range(len(I_diffuse)):\n","            I_Temp = I_diffuse[i].permute(0, 3, 1, 2) # [#Pattern, R, C, 3] -> [#Pattern, 3, R, C]\n","            I_diffuse_G[i] = transform(I_Temp).permute(0, 2, 3, 1) # [#Pattern, 3, R, C] -> [#Pattern, R, C, 3]\n","        I_diffuse = torch.clamp(I_diffuse_G, 1e-8, 1)\n","        '''\n","        return I_diffuse\n","\n","# reconstructor.py -------------------------------------------------------------\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","#import utils\n","from PIL import Image\n","import cv2\n","import torch\n","import torch.nn as nn\n","import datetime\n","import os\n","\n","class Reconstructor:\n","    def __init__(self, opt):\n","        super().__init__()\n","        self.opt = opt\n","\n","\n","    def forward(self, im_diffuse, light_pattern_nonlinear, incident, camera_gain, mask):\n","        batch_size = im_diffuse.shape[0]\n","\n","        normal, albedo, depth = self.photometric_stereo(batch_size, im_diffuse, light_pattern_nonlinear, incident, camera_gain, mask)\n","\n","        recon_dict = {\n","            'normal': normal,\n","            'albedo': albedo,\n","            'depth' : depth\n","        }\n","\n","        return recon_dict\n","\n","    def photometric_stereo(self, batch_size, im_rendered, light_pattern_nonlinear, incident, camera_gain, mask):\n","        \"\"\"\n","        Args:\n","            im_rendered: rendered image while training, real photo while testing\n","                    : [batch_size, #patterns, camR, camC, rgb] -> [batch_size, #patterns, camR, camC, rgb] -> [batch_size, #patterns, camR*camC]\n","            light_pattern_nonlinear: illumination\n","                    : sigmoid() -> [#patterns, lightR, lightC, rgb] -> [#patterns, lightR, lightC, 1] -> [#pattenrs, lightR*lightC]\n","            light_pos: coordinate of monitor\n","                    : [lightR, lightC, xyz] -> light_direction\n","            ptcloud: reference for photometric stereo, PLANE-NO(we assume that all data point is one same point)\n","            camera_gain: gain parameter for optimizing\n","        Output:\n","            surface normal: (batch, R, C, RGB) reconstructed normals\n","            diffuse albedo: (batch, R, C, RGB) reconstructed diffuse albedo\n","            depth map     : (batch, R, C, RGB) reconstructed depths\n","            valid mask\n","        \"\"\"\n","        light_num = self.opt.light_N\n","        monitor_light_radiance = torch.sigmoid(light_pattern_nonlinear)**self.opt.monitor_gamma\n","        input_R, input_C = im_rendered.shape[2:4]\n","\n","        incident = incident.reshape(self.opt.light_R*self.opt.light_C, batch_size*input_R*input_C, 3).permute(1,0,2)\n","        diffuse_albedo = torch.max(im_rendered, dim=1).values\n","\n","        r = diffuse_albedo[:,:,:,0].reshape(batch_size*input_R*input_C, 1, 1)\n","        g = diffuse_albedo[:,:,:,1].reshape(batch_size*input_R*input_C, 1, 1)\n","        b = diffuse_albedo[:,:,:,2].reshape(batch_size*input_R*input_C, 1, 1)\n","\n","        # im_rendered: [batch, #pattern, R, C, 3] -> [batch*R*C, 3*#pattern]\n","        im_rendered = im_rendered.permute(0,2,3,4,1) # batch, R, C, 3, #pattern\n","        im_rendered = im_rendered.reshape(batch_size*input_R*input_C, 3*light_num)\n","        im_rendered = im_rendered.unsqueeze(-1)\n","\n","        im_rendered_red = im_rendered[:, :light_num]\n","        im_rendered_green = im_rendered[:, light_num:2*light_num]\n","        im_rendered_blue = im_rendered[:, 2*light_num:3*light_num]\n","\n","        # light_pattern: [#pattern, r, c, 3] -> [3*#pattern, r*c]\n","        monitor_light_radiance = monitor_light_radiance.permute(3,0,1,2)\n","        monitor_light_radiance = monitor_light_radiance.reshape(3*light_num, self.opt.light_R*self.opt.light_C)\n","\n","        # M: [3*#pattern, 3] -> [3*#pattern, xyz, R*C]\n","        # => M1:r, M2:g, M3:b   [#patterns, xyz, R*C]\n","        monitor_light_radiance = torch.tile(monitor_light_radiance.unsqueeze(0), (batch_size * input_R * input_C, 1, 1))\n","        M = monitor_light_radiance @ (incident)\n","        M1 = M[:, 0:light_num, :]\n","        M2 = M[:, light_num:2*light_num, :]\n","        M3 = M[:, 2*light_num:3*light_num, :]\n","\n","        # iterative update\n","        for i in range(1):\n","            M_temp = torch.zeros_like(M, dtype=torch.float32, device=self.opt.device)\n","            # element-wise multiplication\n","            M_temp[:, 0:light_num, :] = r * M1\n","            M_temp[:, light_num:2 * light_num, :] = g * M2\n","            M_temp[:, 2 * light_num:3 * light_num, :] = b * M3\n","            # solve normal\n","            # invM: [3, 3*#patterns]\n","            # x:    [3, batch*R*C]\n","            print(M_temp.shape,im_rendered.shape)\n","            x = torch.linalg.lstsq(M_temp, im_rendered).solution\n","\n","            x = (x.squeeze(-1))\n","\n","            # black-pixel handling\n","            x = x/(torch.linalg.norm(x, axis=-1).unsqueeze(-1) + 1e-8)\n","            x = x.unsqueeze(-1)\n","\n","            # solve each channel\n","            # invR/G/B: [batch_size*camR*camC, 1, 9]\n","\n","            #------------------------------------------------------------------------------\n","            foreshortening = torch.clamp(incident@x, 1e-8, None)\n","            r_expose = monitor_light_radiance[:,0:light_num,:]@foreshortening\n","            g_expose = monitor_light_radiance[:,light_num:2*light_num,:]@foreshortening\n","            b_expose = monitor_light_radiance[:,2*light_num:3*light_num,:]@foreshortening\n","\n","            r_new = (torch.linalg.lstsq(r_expose, im_rendered_red).solution)\n","            g_new = (torch.linalg.lstsq(g_expose, im_rendered_green).solution)\n","            b_new = (torch.linalg.lstsq(b_expose, im_rendered_blue).solution)\n","\n","\n","            r_ = r_new.reshape(batch_size, input_R, input_C)\n","            g_ = g_new.reshape(batch_size, input_R, input_C)\n","            b_ = b_new.reshape(batch_size, input_R, input_C)\n","\n","            diffuse_albedo = torch.stack([r_, g_, b_], axis=-1)\n","\n","            gain_scalar = self.opt.cam_gain_base ** (torch.sigmoid(camera_gain)*48)\n","\n","            diffuse_albedo = diffuse_albedo / (gain_scalar * (self.opt.rendering_scalar * self.opt.cam_shutter_time) + 1e-8)\n","            diffuse_albedo = torch.clamp(diffuse_albedo, 1e-8, 1)\n","\n","            surface_normal = x.reshape(batch_size, input_R, input_C, 3)\n","            normal_map = surface_normal.clone()\n","            surface_normal = (1-surface_normal)/2\n","            surface_normal = torch.clamp(surface_normal, 1e-8, 1)\n","\n","            #normal_map = surface_normal.clone()\n","            #pnum = input_R*input_C\n","            # surface_normal: [batch, R, C, 3] -> [3, batch*R*C]\n","            #print(normal_map.shape)\n","            #normal_map = normal_map.permute(3,0,1,2) # 3, batch, R, C\n","            #normal_map = normal_map.reshape(3, batch_size*input_R*input_C)\n","            #normal_x = normal_map[0,:]\n","            #normal_y = normal_map[1,:]\n","            #normal_z = normal_map[2,:]\n","\n","            #A_temp = torch.zeros(batch_size*2*pnum, dtype=torch.float32, device=self.opt.device)\n","            #A_temp[0:pnum] = normal_z[:]\n","            #A_temp[pnum:pnum*2] = normal_z[:]\n","            #A_temp = torch.diag(A_temp)\n","            #print(A_temp.shape)\n","\n","            A_tmp = torch.zeros(batch_size,input_R,input_C,3,dtype=torch.float32, device=self.opt.device)\n","            #B_tmp = torch.zeros(batch_size,input_R,input_C,3,dtype=torch.float32, device=self.opt.device)\n","            z0 = torch.zeros(1,dtype=torch.float32, device=self.opt.device) #(m)\n","            z0[0] = 0\n","            k = 1\n","            # naive approach\n","            for i in range(input_R-1,0,-1):\n","              for j in range(input_C-1,0,-1):\n","                if mask[i][j] == 0:\n","                  continue\n","                if j == input_C-1 or mask[i][j+1] == 0:\n","                  ret = z0[0] + k*self.opt.cam_pitch * normal_map[0][i][j][0]/normal_map[0][i][j][2]\n","                else:\n","                  ret = A_tmp[0][i][j+1][0] + k*self.opt.cam_pitch * normal_map[0][i][j][0]/normal_map[0][i][j][2]\n","\n","                if i == input_R-1 or mask[i+1][j] == 0:\n","                  ret += z0[0] + k*self.opt.cam_pitch * normal_map[0][i][j][1]/normal_map[0][i][j][2]\n","                else:\n","                  ret += A_tmp[0][i+1][j][0] + k*self.opt.cam_pitch * normal_map[0][i][j][1]/normal_map[0][i][j][2]\n","\n","                for k in range(3):\n","                    A_tmp[0][i][j][k] = ret/2\n","\n","            A_max = torch.max(A_tmp)\n","            A_min = torch.min(A_tmp)\n","            #print(A_max,A_min,A_tmp)\n","            A_tmp = torch.sub(A_tmp, A_min)\n","            A_tmp = torch.div(A_tmp,(A_max-A_min))\n","            A_tmp = torch.clamp(A_tmp, 1e-8, 1)\n","            depth_map = A_tmp\n","            '''\n","            for i in range(input_R):\n","              for j in range(input_C):\n","                if i == 0:\n","                  ret = z0[0] - self.opt.cam_pitch * normal_map[0][i][j][1]/normal_map[0][i][j][2]\n","                  for k in range(3):\n","                    B_tmp[0][i][j][k] = ret\n","                else:\n","                  ret = B_tmp[0][i-1][j][0] - self.opt.cam_pitch* normal_map[0][i][j][1]/normal_map[0][i][j][2]\n","                  for k in range(3):\n","                    B_tmp[0][i][j][k] = ret\n","\n","                if j == 0:\n","                  #ret = z0[0] + self.opt.cam_pitch * surface_normal[0][i][j][0]/surface_normal[0][i][j][2]\n","                  ret = z0[0] - self.opt.cam_pitch * normal_map[0][i][j][0]/normal_map[0][i][j][2]\n","                  for k in range(3):\n","                    A_tmp[0][i][j][k] = ret\n","                else:\n","                  #ret = A_tmp[0][i][j+1][0] + self.opt.cam_pitch* surface_normal[0][i][j][0]/surface_normal[0][i][j][2]\n","                  ret = A_tmp[0][i][j-1][0] - self.opt.cam_pitch* normal_map[0][i][j][0]/normal_map[0][i][j][2]\n","                  for k in range(3):\n","                    A_tmp[0][i][j][k] = ret\n","            A_max = torch.max(A_tmp)\n","            A_min = torch.min(A_tmp)\n","            print(A_max,A_min,A_tmp)\n","            A_tmp = torch.sub(A_tmp, A_min)\n","            A_tmp = torch.div(A_tmp,(A_max-A_min))\n","            A_tmp = torch.clamp(A_tmp, 1e-8, 1)\n","            B_max = torch.max(B_tmp)\n","            B_min = torch.min(B_tmp)\n","            print(B_max,B_min,B_tmp)\n","            B_tmp = torch.sub(B_tmp, B_min)\n","            B_tmp = torch.div(B_tmp,(B_max-B_min))\n","            B_tmp = torch.clamp(B_tmp, 1e-8, 1)\n","\n","            depth_map = A_tmp\n","            depth_map += B_tmp\n","            depth_map = torch.div(depth_map,2)\n","            '''\n","\n","            #print(depth_map)\n","\n","            #print(A_tmp.shape,A_tmp)\n","\n","\n","\n","        return surface_normal, diffuse_albedo, depth_map\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2N25WU0_m0nn","outputId":"cfc2befc-a3e5-4fc3-91fc-e3c30f2cd275","executionInfo":{"status":"ok","timestamp":1732422697721,"user_tz":-540,"elapsed":50750,"user":{"displayName":"김형준","userId":"06685130616941328722"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["------------ Options -------------\n","-------------- End ----------------\n","=================================================================================\n","Reconstruction output: ./results_apply/debug/20241124_043045\n","=================================================================================\n","torch.Size([277248, 12, 3]) torch.Size([277248, 12, 1])\n","tensor(0.0034, device='cuda:0', grad_fn=<MaxBackward1>) tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor([[[[0., 0., 0.],\n","          [0., 0., 0.],\n","          [0., 0., 0.],\n","          ...,\n","          [0., 0., 0.],\n","          [0., 0., 0.],\n","          [0., 0., 0.]],\n","\n","         [[0., 0., 0.],\n","          [0., 0., 0.],\n","          [0., 0., 0.],\n","          ...,\n","          [0., 0., 0.],\n","          [0., 0., 0.],\n","          [0., 0., 0.]],\n","\n","         [[0., 0., 0.],\n","          [0., 0., 0.],\n","          [0., 0., 0.],\n","          ...,\n","          [0., 0., 0.],\n","          [0., 0., 0.],\n","          [0., 0., 0.]],\n","\n","         ...,\n","\n","         [[0., 0., 0.],\n","          [0., 0., 0.],\n","          [0., 0., 0.],\n","          ...,\n","          [0., 0., 0.],\n","          [0., 0., 0.],\n","          [0., 0., 0.]],\n","\n","         [[0., 0., 0.],\n","          [0., 0., 0.],\n","          [0., 0., 0.],\n","          ...,\n","          [0., 0., 0.],\n","          [0., 0., 0.],\n","          [0., 0., 0.]],\n","\n","         [[0., 0., 0.],\n","          [0., 0., 0.],\n","          [0., 0., 0.],\n","          ...,\n","          [0., 0., 0.],\n","          [0., 0., 0.],\n","          [0., 0., 0.]]]], device='cuda:0', grad_fn=<CopySlices>)\n","tensor([[[[1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          ...,\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08]],\n","\n","         [[1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          ...,\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08]],\n","\n","         [[1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          ...,\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08]],\n","\n","         ...,\n","\n","         [[1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          ...,\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08]],\n","\n","         [[1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          ...,\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08]],\n","\n","         [[1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          ...,\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08]]]], device='cuda:0',\n","       grad_fn=<ClampBackward1>)\n","./results_apply/debug/20241124_043045/normal_est_dragonite.png saved\n","./results_apply/debug/20241124_043045/albedo_est_dragonite.png saved\n","./results_apply/debug/20241124_043045/depth_est_dragonite.png saved\n","torch.Size([277248, 12, 3]) torch.Size([277248, 12, 1])\n","tensor(0.0042, device='cuda:0', grad_fn=<MaxBackward1>) tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor([[[[0., 0., 0.],\n","          [0., 0., 0.],\n","          [0., 0., 0.],\n","          ...,\n","          [0., 0., 0.],\n","          [0., 0., 0.],\n","          [0., 0., 0.]],\n","\n","         [[0., 0., 0.],\n","          [0., 0., 0.],\n","          [0., 0., 0.],\n","          ...,\n","          [0., 0., 0.],\n","          [0., 0., 0.],\n","          [0., 0., 0.]],\n","\n","         [[0., 0., 0.],\n","          [0., 0., 0.],\n","          [0., 0., 0.],\n","          ...,\n","          [0., 0., 0.],\n","          [0., 0., 0.],\n","          [0., 0., 0.]],\n","\n","         ...,\n","\n","         [[0., 0., 0.],\n","          [0., 0., 0.],\n","          [0., 0., 0.],\n","          ...,\n","          [0., 0., 0.],\n","          [0., 0., 0.],\n","          [0., 0., 0.]],\n","\n","         [[0., 0., 0.],\n","          [0., 0., 0.],\n","          [0., 0., 0.],\n","          ...,\n","          [0., 0., 0.],\n","          [0., 0., 0.],\n","          [0., 0., 0.]],\n","\n","         [[0., 0., 0.],\n","          [0., 0., 0.],\n","          [0., 0., 0.],\n","          ...,\n","          [0., 0., 0.],\n","          [0., 0., 0.],\n","          [0., 0., 0.]]]], device='cuda:0', grad_fn=<CopySlices>)\n","tensor([[[[1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          ...,\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08]],\n","\n","         [[1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          ...,\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08]],\n","\n","         [[1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          ...,\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08]],\n","\n","         ...,\n","\n","         [[1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          ...,\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08]],\n","\n","         [[1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          ...,\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08]],\n","\n","         [[1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          ...,\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08]]]], device='cuda:0',\n","       grad_fn=<ClampBackward1>)\n","./results_apply/debug/20241124_043045/normal_est_fox.png saved\n","./results_apply/debug/20241124_043045/albedo_est_fox.png saved\n","./results_apply/debug/20241124_043045/depth_est_fox.png saved\n","torch.Size([277248, 12, 3]) torch.Size([277248, 12, 1])\n","tensor(0.0036, device='cuda:0', grad_fn=<MaxBackward1>) tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor([[[[0., 0., 0.],\n","          [0., 0., 0.],\n","          [0., 0., 0.],\n","          ...,\n","          [0., 0., 0.],\n","          [0., 0., 0.],\n","          [0., 0., 0.]],\n","\n","         [[0., 0., 0.],\n","          [0., 0., 0.],\n","          [0., 0., 0.],\n","          ...,\n","          [0., 0., 0.],\n","          [0., 0., 0.],\n","          [0., 0., 0.]],\n","\n","         [[0., 0., 0.],\n","          [0., 0., 0.],\n","          [0., 0., 0.],\n","          ...,\n","          [0., 0., 0.],\n","          [0., 0., 0.],\n","          [0., 0., 0.]],\n","\n","         ...,\n","\n","         [[0., 0., 0.],\n","          [0., 0., 0.],\n","          [0., 0., 0.],\n","          ...,\n","          [0., 0., 0.],\n","          [0., 0., 0.],\n","          [0., 0., 0.]],\n","\n","         [[0., 0., 0.],\n","          [0., 0., 0.],\n","          [0., 0., 0.],\n","          ...,\n","          [0., 0., 0.],\n","          [0., 0., 0.],\n","          [0., 0., 0.]],\n","\n","         [[0., 0., 0.],\n","          [0., 0., 0.],\n","          [0., 0., 0.],\n","          ...,\n","          [0., 0., 0.],\n","          [0., 0., 0.],\n","          [0., 0., 0.]]]], device='cuda:0', grad_fn=<CopySlices>)\n","tensor([[[[1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          ...,\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08]],\n","\n","         [[1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          ...,\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08]],\n","\n","         [[1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          ...,\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08]],\n","\n","         ...,\n","\n","         [[1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          ...,\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08]],\n","\n","         [[1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          ...,\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08]],\n","\n","         [[1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          ...,\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08],\n","          [1.0000e-08, 1.0000e-08, 1.0000e-08]]]], device='cuda:0',\n","       grad_fn=<ClampBackward1>)\n","./results_apply/debug/20241124_043045/normal_est_square.png saved\n","./results_apply/debug/20241124_043045/albedo_est_square.png saved\n","./results_apply/debug/20241124_043045/depth_est_square.png saved\n"]}],"source":["# Train.py (Main) --------------------------------------------------------------\n","\n","import time\n","import torch\n","from torch.utils.data import DataLoader, random_split\n","from torch.utils.tensorboard import SummaryWriter\n","from tqdm import tqdm\n","\n","def train(Opt, apply_dataset):\n","    # Option\n","    opt = Opt\n","    print('=================================================================================')\n","    print('Reconstruction output: %s' % opt.tb_dir)\n","    print('=================================================================================')\n","\n","    # Image formation & Reconstruction & Trainer\n","    recon_model = Reconstructor(opt)\n","    trainer = Trainer(opt, recon_model)\n","\n","    for k, v in enumerate(apply_dataset.scene_names):\n","      model_results = trainer.run_model(apply_dataset,k)\n","      results = model_results_to_np(model_results, batch_ind=0)\n","      normal_est = (results['normal_est']*255).astype(np.uint8)\n","      albedo_est = (results['albedo_est']*255).astype(np.uint8)\n","      depth_est = (results['depth_est']*255).astype(np.uint8)\n","      img_normal = Image.fromarray(normal_est)\n","      img_normal.save(opt.tb_dir+f'/normal_est_{v}.png','PNG')\n","      print(opt.tb_dir+f\"/normal_est_{v}.png saved\")\n","      img_albedo = Image.fromarray(albedo_est)\n","      img_albedo.save(opt.tb_dir+f'/albedo_est_{v}.png','PNG')\n","      print(opt.tb_dir+f\"/albedo_est_{v}.png saved\")\n","      img_depth = Image.fromarray(depth_est)\n","      img_depth.save(opt.tb_dir+f'/depth_est_{v}.png','PNG')\n","      print(opt.tb_dir+f\"/depth_est_{v}.png saved\")\n","\n","# Main\n","opt = Options().parse(save=True, isTrain=True)\n","apply_dataset = CreateBasisDataset(opt, 'Apply_Data')\n","train(opt,apply_dataset)\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[{"file_id":"1Kzyy-TrMfKrVciIon6H7-_xzTfF5uDSv","timestamp":1730408335773}],"authorship_tag":"ABX9TyM2Awj2jYn/X/yDzOYVt6N/"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}